{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "This notebook provides an example of how to use SML to read in a dataset, split the data into training and testing data, replace troublesome values such as 'NaNs' from the dataset, perform classifcation on the dataset, and Lastly, generates lattice plots, other visual metrics. For this use-case we use **'publicly'?** availiable dataset [Titanic Data Set]https://www.kaggle.com/c/titanic/data) and use Random Forest  to classify the MPG.\n",
    "\n",
    "## SML Query\n",
    "### Imports\n",
    "We import the nescessary library to use SML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sml import execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query\n",
    "Next we create a query statement to `READ` in the data and the file is delimited by a fixed width, the header is not used, next we `REPLACE` any values of 'NaN' with the mode of the column, `SPLIT` the dataset and use 80% of it for training and 20% of it for testing, and lastly, we perform random forest classification on the 2nd column, using columns 1, 3-8 as the predictiors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = 'READ \"../data/titanic.csv\" (separator = \",\", header = 0) AND\\\n",
    "REPLACE (\"NaN\", \"mode\") AND SPLIT (train = .8, test = 0.2) AND\\\n",
    "CLASSIFY (predictors = [1,3,4,5,6,7,8,9,10,11,12], label = 2, algorithm = forest)'\n",
    "\n",
    "execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually\n",
    "\n",
    "The subsequent cells below show how the same actions of a SML query can be performed manually.\n",
    "\n",
    "### Imports\n",
    "Here we import the necessary libraries needed to perform the same actions as the SML query above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries required for ML\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Encoders/Imputers \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read\n",
    "\n",
    "Read in the titanic dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pd.read_csv(\"../data/titanic.csv\", sep = \",\", header = 0)\n",
    "f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPLACE\n",
    "\n",
    "Next we drop convert all of NaNs with the mode of that particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare    Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  B96 B98        S  \n",
       "1      0          PC 17599  71.2833      C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  B96 B98        S  \n",
       "3      0            113803  53.1000     C123        S  \n",
       "4      0            373450   8.0500  B96 B98        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "impute_missing()\n",
    "Parameters:\n",
    "  data: Dataframe to impute missing values on\n",
    "  columns: Columns to impute. If None, impute all columns\n",
    "  impute_strategy: What to replace missing values with\n",
    "     Options: \n",
    "      Imputer Class\n",
    "      'most frequent'\n",
    "      'median'\n",
    "      'mean'\n",
    "      Custom Functions\n",
    "      'remove'\n",
    "      'dummy'\n",
    "      'rand_forest_reg'\n",
    "Returns: Imputed dataframe\n",
    "\"\"\"\n",
    "def impute_missing(data, columns=None, impute_strategy='mode', missing_values='NaN'):\n",
    "  datacopy = data\n",
    "  dummy_val = 'U0'\n",
    "  cols_to_impute = list()\n",
    "  if columns == None:\n",
    "    cols_to_impute = _find_cols_with_missing_vals(data, missing_values)\n",
    "  else:\n",
    "    cols_to_impute = columns\n",
    "  if impute_strategy == 'mode':\n",
    "    for col in cols_to_impute:\n",
    "      modeVal = data[col].mode()\n",
    "      datacopy[col] = data[col].fillna(modeVal[0])\n",
    "    return datacopy\n",
    "  elif impute_strategy == 'mean':\n",
    "    for col in cols_to_impute:\n",
    "      meanVal = data[col].mean()\n",
    "      datacopy[col] = data[col].fillna(meanVal)\n",
    "    return datacopy\n",
    "  elif impute_strategy == 'median':\n",
    "    for col in cols_to_impute:\n",
    "      medianVal = data[col].median()\n",
    "      datacopy[col] = data[col].fillna(medianVal)\n",
    "    return datacopy\n",
    "  elif impute_strategy == 'drop column':\n",
    "    return _remove_columns(data, cols_to_impute)\n",
    "  elif impute_strategy == 'maximum':\n",
    "    for col in cols_to_impute:\n",
    "      maxVal = max(data[col])\n",
    "      datacopy[col] = data[col].fillna(maxVal)\n",
    "    return data\n",
    "  elif impute_strategy == 'minimum':\n",
    "    for col in cols_to_impute:\n",
    "      minVal = min(data[col])\n",
    "      datacopy[col] = data[col].fillna(minVal)\n",
    "    return data\n",
    "  elif impute_strategy == 'dummy':\n",
    "    return data.replace(missing_values, dummy_val) \n",
    "  # Do some more research on this before implementing\n",
    "  elif impute_strategy == 'rand_forest_reg':\n",
    "    print(\"RANDOM FOREST REGRESSOR NOT IMPLEMENTED NO IMPUTATION HAPPENED\")\n",
    "    return None\n",
    "  else:\n",
    "    print (\"REPLACE COMMAND NOT RECOGNIZED\")\n",
    "    return None\n",
    "\n",
    "\"\"\"\n",
    "remove_columns()\n",
    "Parameters:\n",
    "  data: dataframe to remove columns\n",
    "  delete_list: list of names of columns to delete\n",
    "Returns:\n",
    "  Dataframe with deleted columns \n",
    "\"\"\"\n",
    "def _remove_columns(data, delete_list):\n",
    "  for col in delete_list:\n",
    "      del data[col]\n",
    "  return data\n",
    "\n",
    "def _find_cols_with_missing_vals(data= None, missing_values= 'NaN'):\n",
    "  cols_to_impute = list()\n",
    "  if missing_values == 'NaN':\n",
    "    for col in f.columns:\n",
    "      if(data[col].isnull().values.any()):\n",
    "        cols_to_impute.append(col)\n",
    "  else:\n",
    "    for col in f.columns:\n",
    "      if missing_values in data[col]:\n",
    "        cols_to_impute.append(col)\n",
    "  return cols_to_impute\n",
    "\n",
    "\n",
    "f_imputed = impute_missing(f)\n",
    "f_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Here we have to encode columns and make them catergorical if they are not numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_categorical(df):\n",
    "    categorical = list()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            categorical.append(col)\n",
    "    for feature in categorical:\n",
    "        l = list(df[feature])\n",
    "        s = set(l)\n",
    "        l2 = list(s)\n",
    "        numbers = list()\n",
    "        for i in range(0,len(l2)):\n",
    "            numbers.append(i)\n",
    "        df[feature] = df[feature].replace(l2, numbers)\n",
    "    return df\n",
    "\n",
    "f_encoded = encode_categorical(f_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT\n",
    "Here we seperate the Labels and Features. (The Dataset is split in the cross_validation sklearn function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seperate features/labels\n",
    "labels = f_encoded['Survived']\n",
    "features = f_encoded.drop('Survived',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFY\n",
    "\n",
    "We fit our Decision Model model with our training dataset and make predictions on our testing dataset and display the accuracy (This is all occurs within the cross_validation function). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.828361139484735"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(n_estimators=100)\n",
    "rand_forest_scores = cross_validation.cross_val_score(rand_forest, \n",
    "                                                      features,\n",
    "                                                      labels,\n",
    "                                                      cv=10,\n",
    "                                                      scoring='accuracy')\n",
    "\n",
    "rand_forest_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
