{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an example of how to use SML to read in a dataset, split the data into training and testing data, replace troublesome such as NaNs from the dataset, and perform classifcation on the dataset. For this use-case we use publicly availiable [US Census Data from 1990](https://archive.ics.uci.edu/ml/datasets/US+Census+Data+%281990%29) and use logistic regression to classify incomes. **[Clarify with Mike]**.\n",
    "\n",
    "**[ Why are we Preprocessing Census Data??]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SML Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Imports\n",
    "\n",
    "We Make the nescessary imports to use sml to read in the dataset, split the dataset into training and testing data, replace troublesome values from the dataset and perform classifcation on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sml import execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a query statement to `READ` in the data and the file is delimited by ',', the header is not used, and the types of values are numeric and string, next we `REPLACE` any values of NaN with the mode of the column, `SPLIT` the dataset and use 80% of it for training and 20% of it for testing, and lastly, we perform classification using logistic regression on the 15th column, using columns 1-14 as the predictiors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = 'READ \"../data/census.csv\" (separator=\",\", header = 0, types = [1:numeric, 2:string]) AND \\\n",
    "            REPLACE (\"NaN\", \"mode\") AND SPLIT (train = .8, test = 0.2) AND \\\n",
    "            CLASSIFY (predictors=[1,2,3,4,5 , 6,7, 8, 9, 10 ,11 ,12, 13,14], label = 15, algorithm = logistic)'\n",
    "\n",
    "execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually\n",
    "\n",
    "The subsequent cells below show how the same actions of a SML query can be performed manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Imports\n",
    "\n",
    "Here we import the necessary libraries needed to perform the same actions as the SML query above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### READ\n",
    "\n",
    "By default the 1990 Census Dataset does not include it's headers, so we specify it manually, and read that file into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "         'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "         'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "data = pd.read_csv('../data/census.csv', names = names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "Next we have to encode categorical values so this can be passed into the sklearn machine learning library to perform logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_categorical(df, cols=None):\n",
    "    categorical = list()\n",
    "    if cols is not None:\n",
    "        categorical = cols\n",
    "    else:\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'object':\n",
    "                categorical.append(col)\n",
    "\n",
    "    for feature in categorical:\n",
    "        l = list(df[feature])\n",
    "        s = set(l)\n",
    "        l2 = list(s)\n",
    "        numbers = list()\n",
    "        for i in range(0,len(l2)):\n",
    "            numbers.append(i)\n",
    "        df[feature] = df[feature].replace(l2, numbers)\n",
    "    return df\n",
    "\n",
    "data_encoded = encode_categorical(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Replace\n",
    "\n",
    "We impute missing values in our panadas dataframe to account for NaNs in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ImputeCategorical(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.imputer = None\n",
    "    def fit(self, data, target=None):\n",
    "        if self.columns is None:\n",
    "            self.columns = data.columns\n",
    "        self.imputer = Imputer(missing_values=0, strategy='most_frequent')\n",
    "        self.imputer.fit(data[self.columns])\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Uses the encoders to transform a data frame.\n",
    "        \"\"\"\n",
    "        output = data.copy()\n",
    "        output[self.columns] = self.imputer.transform(output[self.columns])\n",
    "\n",
    "        return output\n",
    "imputer = ImputeCategorical(['workclass', 'native-country', 'occupation'])\n",
    "data = imputer.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SPLIT\n",
    "\n",
    "We then seperate our labels from our features and use a sklearn function to perform a 80%/20% split our training and testing dataset respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = data['income']\n",
    "features = data.drop('income',1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CLASSIFY\n",
    "\n",
    "Lastly we fit our logistic regression  with our training dataset and make predictions on our testing dataset and display the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.798224925109\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "pred = logreg.predict(X_test)\n",
    "\n",
    "logreg_scores = cross_validation.cross_val_score(logreg, features, labels,\n",
    "                                                 cv=10, scoring='accuracy')\n",
    "\n",
    "print(\"Accuracy: %s\" % logreg_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
